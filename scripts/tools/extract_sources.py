#!/usr/bin/env python3
"""Extrai ocorrências de 'Source' dos XML e gera INSERTs para core_books.
Gera: scripts/init_db/core/insert_books_from_xml.sql
"""
import re
import xml.etree.ElementTree as ET
from pathlib import Path

ROOT = Path(__file__).resolve().parents[2]
XML_FILE = ROOT / 'data' / 'xml' / 'Complete_Compendium_2014.xml'
OUT_SQL = ROOT / 'scripts' / 'init_db' / 'core' / 'insert_books_from_xml.sql'
SCHEMA_FILE = ROOT / 'scripts' / 'init_db' / 'core' / 'schema_books.sql'

# heurísticas para marcar como não-oficial
NON_OFFICIAL_HINTS = [
    'homebrew', 'third party', 'extra life', 'home bre', 'beyound', 'beyond', 'scrapped', 'fan', 'unofficial'
]

RE_SOURCE = re.compile(r'Source:\s*(.+?)(?:<|$|\n)', re.IGNORECASE)
RE_PAGE = re.compile(r'\s*(?:p\.|page)\s*\d+.*$', re.IGNORECASE)
RE_PAGE_CAPTURE = re.compile(r'\b(?:p\.|page)\s*(\d+)\b', re.IGNORECASE)
RE_YEAR = re.compile(r'\((\d{4})\)')
RE_PARENS_TRAIL = re.compile(r'\s*\([^)]*\)\s*$')

def normalize_name(n: str) -> str:
    if not n:
        return ''
    # remove year parentheses like (2014), non-alnum, normalize spaces, lowercase
    s = re.sub(r"\(\d{4}\)", '', n)
    s = re.sub(r"[^a-z0-9 ]", ' ', s.lower())
    s = re.sub(r"\s+", ' ', s).strip()
    return s

# load existing books from schema (extract code,name)
existing = {}
with SCHEMA_FILE.open('r', encoding='utf-8') as fh:
    for line in fh:
        m = re.match(r"\s*\('([^']+)'\s*,\s*'((?:[^']|'')+)'\s*,\s*([^)]*)\)\s*,?", line)
        if m:
            code = m.group(1)
            name = m.group(2).replace("''", "'").strip()
            existing[name.lower()] = code

# also include existing books from current DB (if present) to avoid generating duplicates
try:
    import sqlite3
    DBPATH = Path('data') / 'database' / 'game_data.db'
    if DBPATH.exists():
        con = sqlite3.connect(str(DBPATH))
        cur = con.cursor()
        cur.execute('SELECT code, name FROM core_books')
        for code, name in cur.fetchall():
            if name:
                existing[name.lower()] = code
        con.close()
except Exception:
    # if DB not available, continue — schema is fallback
    pass

# scan xml files
books = {}
occurrences = {}
occurrence_rows = []  # kept for backward-compatibility but not used
OUT_SOURCES = ROOT / 'scripts' / 'init_db' / 'core' / 'insert_book_sources_from_xml.sql'
OUT_SOURCES.parent.mkdir(parents=True, exist_ok=True)
src_f = OUT_SOURCES.open('w', encoding='utf-8')
src_f.write("-- Generated by scripts/tools/extract_sources.py - INSERTs for core_book_sources\n")
occ_count = 0

if XML_FILE.exists():
    paths = [XML_FILE]
else:
    paths = []
for path in paths:
    # do not pre-load the entire file to save memory; process incrementally when possible
    relpath = str(path.relative_to(ROOT))

    # capture <source>...</source> tags using incremental XML parsing (lower memory, faster)
    try:
        for event, elem in ET.iterparse(path, events=('end',)):
            if elem.tag and elem.tag.lower() == 'source':
                raw_full = ''.join(elem.itertext()).strip()
                page_m = RE_PAGE_CAPTURE.search(raw_full)
                page = page_m.group(0).strip() if page_m else None
                raw_stripped_page = RE_PAGE.sub('', raw_full).strip()
                raw_stripped_tags = re.sub(r'<[^>]+>', '', raw_stripped_page).strip()
                year_m = RE_YEAR.search(raw_stripped_tags)
                year = year_m.group(1) if year_m else None
                clean = RE_PARENS_TRAIL.sub('', raw_stripped_tags).strip()
                lower = raw_full.lower()
                is_official = 1
                for hint in NON_OFFICIAL_HINTS:
                    if hint in lower:
                        is_official = 0
                        break
                clean = re.sub(r'\s*\((?:homebrew|third party|fan)\)','', clean, flags=re.I).strip()
                name = clean
                if not name:
                    elem.clear()
                    continue
                key = name.lower()
                occurrences.setdefault(key, 0)
                occurrences[key] += 1
                if key in books:
                    books[key]['is_official'] = books[key]['is_official'] & is_official
                    if not books[key]['year'] and year:
                        books[key]['year'] = year
                else:
                    matched_code = None
                    for ename, ecode in existing.items():
                        # use normalized matching to avoid creating suffixed codes when a canonical exists
                        if normalize_name(ename) and normalize_name(key) and (
                            normalize_name(ename) in normalize_name(key) or normalize_name(key) in normalize_name(ename)
                        ):
                            matched_code = ecode
                            break
                    def make_code(n):
                        words = [w for w in re.split(r"[^A-Za-z0-9]+", n) if w and w.lower() not in ('and','the','of','in','a','to','from','for')]
                        if not words:
                            return n[:6].upper()
                        code = ''.join(w[0] for w in words).upper()[:6]
                        if len(code) < 2:
                            code = ''.join(w[:2].upper() for w in words)[:6]
                        return code
                    code = matched_code or make_code(name)
                    base = code
                    i = 1
                    existing_codes = set([v for v in existing.values()]) | set(b['code'] for b in books.values())
                    while code in existing_codes:
                        i += 1
                        code = f"{base}{i}"
                    books[key] = {'name': name, 'code': code, 'year': year or None, 'is_official': is_official}

                # write occurrence immediately to reduce memory usage
                raw_esc = raw_full.replace("'", "''")
                page_val = f"'{page}'" if page else 'NULL'
                code_esc = books[key]['code']
                src_f.write(f"INSERT OR IGNORE INTO core_book_sources (book_id, raw_source, page) VALUES ((SELECT id FROM core_books WHERE code='{code_esc}'), '{raw_esc}', {page_val});\n")
                occ_count += 1
                if occ_count % 5000 == 0:
                    print(f"Found {occ_count} occurrences so far...")
                elem.clear()
    except Exception:
        # fallback to regex-based parsing if XML isn't well-formed
        text = path.read_text(encoding='utf-8', errors='ignore')
        for m in re.finditer(r'<source[^>]*>(.*?)</source>', text, flags=re.I|re.S):
            raw_full = m.group(1).strip()
            page_m = RE_PAGE_CAPTURE.search(raw_full)
            page = page_m.group(0).strip() if page_m else None
            raw_stripped_page = RE_PAGE.sub('', raw_full).strip()
            raw_stripped_tags = re.sub(r'<[^>]+>', '', raw_stripped_page).strip()
            year_m = RE_YEAR.search(raw_stripped_tags)
            year = year_m.group(1) if year_m else None
            clean = RE_PARENS_TRAIL.sub('', raw_stripped_tags).strip()
            lower = raw_full.lower()
            is_official = 1
            for hint in NON_OFFICIAL_HINTS:
                if hint in lower:
                    is_official = 0
                    break
            clean = re.sub(r'\s*\((?:homebrew|third party|fan)\)','', clean, flags=re.I).strip()
            name = clean
            if not name:
                continue
            key = name.lower()
            occurrences.setdefault(key, 0)
            occurrences[key] += 1
            if key in books:
                books[key]['is_official'] = books[key]['is_official'] & is_official
                if not books[key]['year'] and year:
                    books[key]['year'] = year
            else:
                matched_code = None
                for ename, ecode in existing.items():
                    if normalize_name(ename) and normalize_name(key) and (
                        normalize_name(ename) in normalize_name(key) or normalize_name(key) in normalize_name(ename)
                    ):
                        matched_code = ecode
                        break
                def make_code(n):
                    words = [w for w in re.split(r"[^A-Za-z0-9]+", n) if w and w.lower() not in ('and','the','of','in','a','to','from','for')]
                    if not words:
                        return n[:6].upper()
                    code = ''.join(w[0] for w in words).upper()[:6]
                    if len(code) < 2:
                        code = ''.join(w[:2].upper() for w in words)[:6]
                    return code
                code = matched_code or make_code(name)
                base = code
                i = 1
                existing_codes = set([v for v in existing.values()]) | set(b['code'] for b in books.values())
                while code in existing_codes:
                    i += 1
                    code = f"{base}{i}"
                books[key] = {'name': name, 'code': code, 'year': year or None, 'is_official': is_official}

            raw_esc = raw_full.replace("'", "''")
            page_val = f"'{page}'" if page else 'NULL'
            code_esc = books[key]['code']
            src_f.write(f"INSERT OR IGNORE INTO core_book_sources (book_id, raw_source, page) VALUES ((SELECT id FROM core_books WHERE code='{code_esc}'), '{raw_esc}', {page_val});\n")
            occ_count += 1

    # capture 'Source: ...' inline occurrences by streaming file lines to avoid large memory spikes
    with path.open('r', encoding='utf-8', errors='ignore') as fh:
        for line in fh:
            for m in RE_SOURCE.finditer(line):
                raw_full = m.group(1).strip()
                raw = raw_full.rstrip(',')
                page_m = RE_PAGE_CAPTURE.search(raw_full)
                page = page_m.group(0).strip() if page_m else None
                raw_stripped_page = RE_PAGE.sub('', raw).strip()
                raw_stripped_tags = re.sub(r'<[^>]+>', '', raw_stripped_page).strip()
                year_m = RE_YEAR.search(raw_stripped_tags)
                year = year_m.group(1) if year_m else None
                clean = RE_PARENS_TRAIL.sub('', raw_stripped_tags).strip()
                lower = raw_full.lower()
                is_official = 1
                for hint in NON_OFFICIAL_HINTS:
                    if hint in lower:
                        is_official = 0
                        break
                clean = re.sub(r'\s*\((?:homebrew|third party|fan)\)','', clean, flags=re.I).strip()
                name = clean
                if not name:
                    continue
                key = name.lower()
                occurrences.setdefault(key, 0)
                occurrences[key] += 1
                if key in books:
                    books[key]['is_official'] = books[key]['is_official'] & is_official
                    if not books[key]['year'] and year:
                        books[key]['year'] = year
                else:
                    matched_code = None
                    for ename, ecode in existing.items():
                        # use normalized matching to avoid creating suffixed codes when a canonical exists
                        if normalize_name(ename) and normalize_name(key) and (
                            normalize_name(ename) in normalize_name(key) or normalize_name(key) in normalize_name(ename)
                        ):
                            matched_code = ecode
                            break
                    def make_code(n):
                        words = [w for w in re.split(r"[^A-Za-z0-9]+", n) if w and w.lower() not in ('and','the','of','in','a','to','from','for')]
                        if not words:
                            return n[:6].upper()
                        code = ''.join(w[0] for w in words).upper()[:6]
                        if len(code) < 2:
                            code = ''.join(w[:2].upper() for w in words)[:6]
                        return code
                    code = matched_code or make_code(name)
                    base = code
                    i = 1
                    existing_codes = set([v for v in existing.values()]) | set(b['code'] for b in books.values())
                    while code in existing_codes:
                        i += 1
                        code = f"{base}{i}"
                    books[key] = {'name': name, 'code': code, 'year': year or None, 'is_official': is_official}

                # write occurrence immediately
                raw_esc = raw_full.replace("'", "''")
                page_val = f"'{page}'" if page else 'NULL'
                code_esc = books[key]['code']
                src_f.write(f"INSERT OR IGNORE INTO core_book_sources (book_id, raw_source, page) VALUES ((SELECT id FROM core_books WHERE code='{code_esc}'), '{raw_esc}', {page_val});\n")
                occ_count += 1
                if occ_count % 5000 == 0:
                    print(f"Found {occ_count} occurrences so far...")


        # try match to existing name (normalized)
        matched_code = None
        for ename, ecode in existing.items():
            if normalize_name(ename) and normalize_name(key) and (
                normalize_name(ename) in normalize_name(key) or normalize_name(key) in normalize_name(ename)
            ):
                matched_code = ecode
                break
        # generate code if not matched
        def make_code(n):
            words = [w for w in re.split(r"[^A-Za-z0-9]+", n) if w and w.lower() not in ('and','the','of','in','a','to','from','for')]
            if not words:
                return n[:6].upper()
            code = ''.join(w[0] for w in words).upper()[:6]
            if len(code) < 2:
                code = ''.join(w[:2].upper() for w in words)[:6]
            return code
        code = matched_code or make_code(name)
        # ensure uniqueness in current set
        base = code
        i = 1
        existing_codes = set([v for v in existing.values()]) | set(b['code'] for b in books.values())
        while code in existing_codes:
            i += 1
            code = f"{base}{i}"
        books[key] = {'name': name, 'code': code, 'year': year or None, 'is_official': is_official}

# write SQL file for books
lines = ["-- Generated by scripts/tools/extract_sources.py - idempotent INSERTs\n"]
for k, v in sorted(books.items(), key=lambda kv: kv[1]['name'].lower()):
    name_esc = v['name'].replace("'", "''")
    code_esc = v['code']
    lines.append("INSERT OR IGNORE INTO core_books (code, name, release_date, is_official) VALUES ('{}', '{}', {}, {});".format(
        code_esc, name_esc, f"'{v['year']}-01-01'" if v['year'] else 'NULL', v['is_official']
    ))

OUT_SQL.parent.mkdir(parents=True, exist_ok=True)
OUT_SQL.write_text('\n'.join(lines), encoding='utf-8')

# finalize occurrences output
src_f.close()
print(f"Found {occ_count} individual 'Source:' occurrences (details written to {OUT_SOURCES}).")

# summary print
print(f"Found {len(books)} unique book names from XML (details written to {OUT_SQL}).")
# occurrence summary printed earlier using occ_count to reflect streaming write (see above)
for v in books.values():
    print(f"- {v['code']} | {v['name']} | year={v['year'] or 'NULL'} | is_official={v['is_official']}")

# write a quick README note
README = OUT_SQL.parent / 'README.md'
README.write_text("This file was generated by scripts/tools/extract_sources.py — run it to refresh INSERTs from XML sources.\n", encoding='utf-8')
print('Done.')
